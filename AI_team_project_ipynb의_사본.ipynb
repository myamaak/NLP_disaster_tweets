{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI team project.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myamaak/NLP_disaster_tweets/blob/master/AI_team_project_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmxzT3RE4iHZ"
      },
      "source": [
        "https://www.notion.so/Term-Project-Guideline-c44f1514da054ad4bc0a1c82526fea5c\n",
        "\n",
        "평가 기준\n",
        "\n",
        "- Good motivation for the project and an explanation of the problem statement\n",
        "- A description of the data\n",
        "- Any hyperparameter and architecture choices that were explored\n",
        "- Presentation of results\n",
        "- Analysis of results\n",
        "- Any insights and discussions relevant to the project\n",
        "- References\n",
        "- (Extra credit) Member's constribution statement\n",
        "    - Please describe each member's contribution in detail. Blind peer review will be conducted after the final presentation.\n",
        "- (Extra credit) Debugging experience worth sharing\n",
        "- (Extra credit) The Github repository with the commit history\n",
        "\n",
        "**Submission Format**: Presentation material + source code = single Colab file\n",
        "**Presentation**: 15 minutes presentation with the submitted materials\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyculuRiSuE9"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import string  \n",
        "import re   \n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, GlobalMaxPooling1D, MaxPool1D, Conv2D, Input, Embedding, Reshape, MaxPool2D, Concatenate\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import MaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGsipTQhONOp",
        "outputId": "6cde1871-bcec-4522-f9c9-9ba7f897270f"
      },
      "source": [
        "#mount to gdrive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSnIj6KiObjP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "2e38af07-f997-487e-d343-6deb708fc27f"
      },
      "source": [
        "train_data = pd.read_csv('/content/gdrive/My Drive/AI Lecture/kaggle/train.csv')\n",
        "test_data = pd.read_csv('/content/gdrive/My Drive/AI Lecture/kaggle/test.csv')\n",
        "train_data.head(5)\n",
        "# test_data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TS1YPg6aMCO",
        "outputId": "b777de0a-ba79-4877-bf74-b011a4692c6a"
      },
      "source": [
        "sample = train_data['text'][304] #noisy data #not disas\n",
        "print(sample)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#PBBan (Temporary:300) avYsss @'aRmageddon | DO NOT KILL | FLAGS ONLY | Fast XP' for Reason\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwXMcO4Vcnh1",
        "outputId": "84dee435-cd5b-494d-be6b-a8642d3f1c4d"
      },
      "source": [
        "print(len(train_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfgJfYQkda23"
      },
      "source": [
        "#remove duplicates in data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zYMtvWfcjSN"
      },
      "source": [
        "train_data.drop_duplicates(subset= 'text', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSI8p1dxc0Kv",
        "outputId": "51dfab48-5ff5-48a7-f4d4-c360958e9eb8"
      },
      "source": [
        "print(len(train_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWJSyfMElrqo"
      },
      "source": [
        "#text cleaning(1) : remove URL, HTML tag, emojis, punctuations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjea9YiHb9oP"
      },
      "source": [
        "text cleaning\n",
        "- remove url\n",
        "- remove html tags\n",
        "- remove emojis\n",
        "- remove punctuations\n",
        "- spelling correction\n",
        "\n",
        "+ convert all charters into lowercase\n",
        "+ tokenization\n",
        "+ removing stopwords\n",
        "+ stemming and lemmatization\n",
        "+ remove the words having length <=2\n",
        "\n",
        "- remove duplicate at the end of cleaning!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypyMhTHzgjpG"
      },
      "source": [
        "def remove_URL(text):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'',text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kw0_AZCHkd4"
      },
      "source": [
        "def remove_HTML(text):\n",
        "    html=re.compile(r'<.*?>')\n",
        "    return html.sub(r'',text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsNXuvONhGl0",
        "outputId": "25cb57eb-88da-40bb-fe0e-50cb4c5746b9"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1c/1f1457fe52d0b30cbeebfd578483cedb3e3619108d2d5a21380dfecf8ffd/emoji-0.6.0.tar.gz (51kB)\n",
            "\r\u001b[K     |██████▍                         | 10kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 20kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 30kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 40kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.6.0-cp36-none-any.whl size=49716 sha256=58d959d3cda59db2b4cafbef6a5a613d322740447779296334e8611b0257ba67\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2c/8b/9dcf5216ca68e14e0320e283692dce8ae321cdc01e73e17796\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0-3c1lirRrA"
      },
      "source": [
        "remove emoji"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gap5ofhJd1"
      },
      "source": [
        "import emoji\n",
        "def remove_emoji(text):\n",
        "  return emoji.demojize(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MgzZL7l426"
      },
      "source": [
        "이모지를 변환 후 기호가 생기기 때문에 remove punctuation을 나중에 해야한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PvLzYTJrKhj"
      },
      "source": [
        "function for removing punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApPLz9Qrd6-p"
      },
      "source": [
        "#remove punctuations\n",
        "\n",
        "import string  \n",
        "import re   \n",
        "\n",
        "punct = string.punctuation  \n",
        "\n",
        "def remove_punct(text):\n",
        "  text  = \"\".join([char for char in text if char not in punct])\n",
        "  text = re.sub('[0-9]+', '', text) #숫자 제거\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbqDYfDRldql"
      },
      "source": [
        "#text cleaning(2):correct spelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syubDnk_mILm"
      },
      "source": [
        "reference : https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SPELL_CHECKER_EN.ipynb#scrollTo=uAiXj3DOfyZ-\n",
        "\n",
        "colab에서는 spellchecker을 쓸 수 없다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nRkEWxPmGbc"
      },
      "source": [
        "dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWf9SU_yli_K",
        "outputId": "1f0a62c4-c82c-4e25-97d6-54f17c0917c3"
      },
      "source": [
        "# Install java\n",
        "!apt-get update -qq\n",
        "!apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "!java -version\n",
        "\n",
        "# Install pyspark\n",
        "!pip install --ignore-installed -q pyspark==2.4.4\n",
        "\n",
        "# Install Sparknlp\n",
        "!pip install --ignore-installed spark-nlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.9.1\" 2020-11-04\n",
            "OpenJDK Runtime Environment (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 72kB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 55.8MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spark-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/26/f7a6ac12339d2f1ed271c46c16705665620059e4559f323695925f3c63b4/spark_nlp-2.6.4-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 7.7MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.6.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y35E3FNcmVLi"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJIs5uNwmfCJ"
      },
      "source": [
        "start spark session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkXPk1o2mXcV"
      },
      "source": [
        "spark = sparknlp.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbBC-XphmiGk"
      },
      "source": [
        "Select the NER model and construct the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8UmJ5twpKbn",
        "outputId": "009b52ec-dc31-48db-c52b-18f0762a3e83"
      },
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "  .setInputCol(\"text\")\\\n",
        "  .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = RecursiveTokenizer()\\\n",
        "  .setInputCols([\"document\"])\\\n",
        "  .setOutputCol(\"token\")\\\n",
        "  .setPrefixes([\"\\\"\", \"(\", \"[\", \"\\n\"])\\\n",
        "  .setSuffixes([\".\", \",\", \"?\", \")\",\"!\", \"‘s\"])\n",
        "\n",
        "spell_model = ContextSpellCheckerModel\\\n",
        "    .pretrained('spellcheck_dl')\\\n",
        "    .setInputCols(\"token\")\\\n",
        "    .setOutputCol(\"corrected\")\n",
        "\n",
        "finisher = Finisher().setInputCols(\"corrected\")\n",
        "\n",
        "light_pipeline = Pipeline(stages = [\n",
        "                                    document_assembler,\n",
        "                                    tokenizer,\n",
        "                                    spell_model,\n",
        "                                    finisher\n",
        "                                    ])\n",
        "\n",
        "empty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "l_pipeline_model = LightPipeline(light_pipeline.fit(empty_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spellcheck_dl download started this may take some time.\n",
            "Approximate size to download 112 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe3gMSriq6vA"
      },
      "source": [
        "function to correct spellings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NTeC3nZpqoR"
      },
      "source": [
        "#input : single text sentence of str\n",
        "# ex) \"Plaese alliow me tao introdduce myhelf, I am a man of waelth und tiaste\"\n",
        "def correct_spelling(text):\n",
        "  result = l_pipeline_model.annotate(text)\n",
        "  result = ' '.join(result['corrected'])\n",
        "  return result\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm3dJU0Rn35N"
      },
      "source": [
        "#text cleaning(3) Convert all charters into lowercase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm06LNvHoC_N"
      },
      "source": [
        "def clean_lowercase(text):\n",
        "  return str(text).lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFtJDr2LoOmj"
      },
      "source": [
        "#text cleaning(4) Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meMwdCe_oXJO",
        "outputId": "019d7e9a-15e2-41eb-e163-47d646f227b8"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "def clean_tokenization(text):\n",
        "  return word_tokenize(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs3MzwMSodBo"
      },
      "source": [
        "#text cleaning(5) Removing stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXcvoC16ohY0"
      },
      "source": [
        "# nltk.download(\"stopwords\")\n",
        "# from nltk.corpus import stopwords\n",
        "# stop_words = set(stopwords.words('english'))\n",
        "# def clean_stopwords(text):\n",
        "#        return [item for item in text if item not in stop_words]\n",
        "\n",
        "stop_words = [\"the\", \"a\", \"to\", \"and\", \"of\"]\n",
        "def clean_stopwords(text):\n",
        "       return [item for item in text if item not in stop_words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPw9qa6wonoO"
      },
      "source": [
        "#text cleaning(6) Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh-R84kNoyjP",
        "outputId": "daadc066-d8ea-41fe-8020-96423f7f539f"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemma=WordNetLemmatizer()\n",
        "nltk.download(\"wordnet\")\n",
        "def clean_lemmatization(token):\n",
        "  return [lemma.lemmatize(word=w,pos='v') for w in token]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFp0Dus8o0ic"
      },
      "source": [
        "#text cleaning(7) Remove the words having length<=2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrSVPWcfo5_Y"
      },
      "source": [
        "def clean_length(token):\n",
        "  return [i for i in token if len(i)>2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xSlZjJU8mja"
      },
      "source": [
        "#text cleaning(8)  Convert the list of tokens into back to the string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS6B3IeP8emx"
      },
      "source": [
        "def convert_tostring(token):\n",
        "  return ' '.join(token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96uIZ45JrfjN"
      },
      "source": [
        "#text cleaning and saving (final)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBfoMAfyrmVQ"
      },
      "source": [
        "def clean(this_text):\n",
        "  this_text = remove_URL(this_text)\n",
        "  this_text = remove_emoji(this_text)\n",
        "  this_text = remove_punct(this_text)\n",
        "  this_text = correct_spelling(this_text)\n",
        "  this_text = clean_lowercase(this_text)\n",
        "  this_text = clean_tokenization(str(this_text))\n",
        "  this_text = clean_stopwords(this_text)\n",
        "  this_text = clean_lemmatization(this_text)\n",
        "  this_text = clean_length(this_text)\n",
        "  this_text = convert_tostring(this_text)\n",
        "  return this_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PvTmDW1jLSLE",
        "outputId": "14903583-f254-4f47-90e7-1a67a26dfff0"
      },
      "source": [
        "clean(sample)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bean  temporary  assess  armageddon  kill  flag  fast  reason'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98NYVrUwMllu"
      },
      "source": [
        "train=[]\n",
        "for i in train_data['text']:\n",
        "  train.append(clean(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fnv0VUseaUS",
        "outputId": "8f604702-78e1-4636-fd3e-2bd9e2d77079"
      },
      "source": [
        "for i in range(len(train_data['text'])):\n",
        "  train_data['text'][i] = train[i]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgjzJrqde4A6"
      },
      "source": [
        "#remove duplicate here\n",
        "\n",
        "train_data.drop_duplicates(subset= 'text', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QnT0SdGffkS",
        "outputId": "25e27759-ad0e-42b6-e4e2-f2188bff116e"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFBB5MQxN1Pn"
      },
      "source": [
        "test=[]\n",
        "for i in test_data['text']:\n",
        "  test.append(clean(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_mfVieSUB9a"
      },
      "source": [
        "with open('/content/gdrive/My Drive/AI Lecture/nlp_train.txt', 'w') as f:\n",
        "    for item in train_data['text']:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOdVE_cKgs09"
      },
      "source": [
        "with open('/content/gdrive/My Drive/AI Lecture/nlp_trainY.txt', 'w') as f:\n",
        "    for item in train_data['target']:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfSMiHrCUOE0"
      },
      "source": [
        "with open('/content/gdrive/My Drive/AI Lecture/nlp_test.txt', 'w') as f:\n",
        "    for item in test:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK57R9sShGMd"
      },
      "source": [
        "train = train_data['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW26vP5dzVwZ"
      },
      "source": [
        "#read saved cleaned data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skGh17jOza6r"
      },
      "source": [
        "trainF = open('/content/gdrive/My Drive/AI Lecture/nlp_train.txt', 'r')\n",
        "train = []\n",
        "for i in trainF:\n",
        "  train.append(i.strip())\n",
        "\n",
        "Y = np.loadtxt('/content/gdrive/My Drive/AI Lecture/nlp_trainY.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUfAAkYyDEIe",
        "outputId": "e8bf127e-986a-46d3-96fc-4964bc050c9f"
      },
      "source": [
        "train[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['our deeds reason this earthquake may allah forgive all',\n",
              " 'forest fire near rong task canada',\n",
              " 'all residents ask shelter place notify officer other evacuation shelter place order expect']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjqPdxp0yb-F"
      },
      "source": [
        "#Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "452nA7cIF2Qo",
        "outputId": "f3754f9e-7211-4100-fe57-15c5e7f22daf"
      },
      "source": [
        "maxlen = 100\n",
        "max_words = 10000\n",
        "\n",
        "tokenizer=Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(train)\n",
        "sequences = tokenizer.texts_to_sequences(train)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 12166 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YBgan4-HMCK",
        "outputId": "afd417f2-f6f2-4f01-90d0-9e1f17d1f208"
      },
      "source": [
        "glove_dir = '/content/gdrive/My Drive/AI Lecture/'\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "# preparing the GloVe word-embeddings matrix\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if i < max_words:\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjDRJt3raCq"
      },
      "source": [
        "X = pad_sequences(sequences,maxlen=maxlen,truncating='post',padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0eOsE0IwLai",
        "outputId": "aec9b560-c842-4ea2-d74a-fbec0e59f5c4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.10, random_state=42)\n",
        "print('Shape of train',X_train.shape)\n",
        "print(\"Shape of test \",X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train (6164, 100)\n",
            "Shape of test  (685, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMvjpF-PkFVE",
        "outputId": "ca3fed1f-4375-4a6a-cfc9-c1626ffa933c"
      },
      "source": [
        "len(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6164"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsscFfuKvWj3"
      },
      "source": [
        "tokenizer=Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(test)\n",
        "sequences = tokenizer.texts_to_sequences(test)\n",
        "\n",
        "test = pad_sequences(sequences,maxlen=maxlen,truncating='post',padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOVQxf0fZU85"
      },
      "source": [
        "#CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhyYJXr5qd3D"
      },
      "source": [
        "분리 합성곱? : https://www.kaggle.com/au1206/text-classification-using-cnn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfKJY-yFZa_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e283e508-5b15-4f55-c40e-9b9d889e6bd2"
      },
      "source": [
        "#baseline model\n",
        "cnn1 = Sequential()\n",
        "cnn1.add(Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable = False))\n",
        "cnn1.add(Conv1D(128, 5, activation='relu'))\n",
        "cnn1.add(MaxPooling1D(5))\n",
        "cnn1.add(Dropout(0.5))\n",
        "cnn1.add(Conv1D(128, 5,activation='relu'))\n",
        "cnn1.add(MaxPooling1D(15))\n",
        "cnn1.add(Flatten())\n",
        "cnn1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "cnn1.compile(loss ='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# dropput rate (what is spatial dropout?), optimizer, convnet size?\n",
        "\n",
        "cnn1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 96, 128)           64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 15, 128)           82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,146,305\n",
            "Trainable params: 146,305\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns7cen9sjL9I"
      },
      "source": [
        "def create_model():\n",
        "  num_filters = 128\n",
        "\n",
        "  Embedding_layer = Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable = False)\n",
        "\n",
        "  input = Input(shape=(maxlen,))\n",
        "  embedding = Embedding_layer(input)\n",
        "\n",
        "  print(embedding.shape)\n",
        "  reshape = Reshape((maxlen,embedding_dim,1))(embedding)\n",
        "  print(reshape.shape)\n",
        "\n",
        "  conv1 = Conv2D(num_filters, kernel_size=(3, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu' , kernel_regularizer='l2')(reshape)\n",
        "  conv2 = Conv2D(num_filters, kernel_size=(4, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer='l2')(reshape)\n",
        "  conv3 = Conv2D(num_filters, kernel_size=(5, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer='l2')(reshape)\n",
        "\n",
        "  maxpooling1 = MaxPool2D(pool_size=(maxlen - 3 + 1, 1), strides=(1,1), padding='valid')(conv1)\n",
        "  maxpooling2 = MaxPool2D(pool_size=(maxlen - 4 + 1, 1), strides=(1,1), padding='valid')(conv2)\n",
        "  maxpooling3 = MaxPool2D(pool_size=(maxlen - 5 + 1, 1), strides=(1,1), padding='valid')(conv3)\n",
        "\n",
        "  concatenated_tensor = Concatenate(axis=1)([maxpooling1, maxpooling2, maxpooling3])\n",
        "  flatten = Flatten()(concatenated_tensor)\n",
        "  dropout = Dropout(0.5)(flatten)\n",
        "  output_layer = Dense(1, activation='sigmoid', kernel_regularizer='l2')(dropout)\n",
        "\n",
        "  # this creates a model that includes\n",
        "  model = Model(inputs=input, outputs=output_layer)\n",
        "\n",
        "  opt = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "  model.compile(loss ='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNp3ypT9lFuo",
        "outputId": "9f3f0a6d-0dcc-4c74-eadf-1d96fbd594de"
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku3gfsdoSv-U"
      },
      "source": [
        "callback = [keras.callbacks.ModelCheckpoint(filepath='best.h5', monitor='val_loss', mode='min', save_best_only=True),\n",
        "            keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto',baseline=None, restore_best_weights=False)]\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=20, shuffle=True, callbacks=callback)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAq27qRMS-8o"
      },
      "source": [
        "#**hyper parameter tunning**\n",
        "\n",
        "1.   batch size\n",
        "2.   optimizer\n",
        "3.   optimizer learning rate\n",
        "4.   l1 vs l2\n",
        "5.   drop out rate\n",
        "6.   ???"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGqYzDdIpz7I"
      },
      "source": [
        "**batch size** ->20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWsrT7F5kGhK"
      },
      "source": [
        "tune_model = KerasClassifier(build_fn = create_model, epochs=30, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k19giSED_I38",
        "outputId": "3de31158-a54a-4036-cb6f-4a459151d7e9"
      },
      "source": [
        "# grid search hyperparameter tunnig\n",
        "batch_size = [4, 10, 20, 40]\n",
        "param_grid = dict(batch_size=batch_size)\n",
        "grid = GridSearchCV(estimator=tune_model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "Best: 0.787963 using {'batch_size': 20}\n",
            "0.772552 (0.012971) with: {'batch_size': 4}\n",
            "0.782610 (0.007310) with: {'batch_size': 10}\n",
            "0.787963 (0.005751) with: {'batch_size': 20}\n",
            "0.783745 (0.006409) with: {'batch_size': 40}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNMu3NaWp3Az"
      },
      "source": [
        "**optimizer** -> SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHeFC2wMpybQ"
      },
      "source": [
        "def create_model(optimizer='adam'):\n",
        "  num_filters = 128\n",
        "\n",
        "  embedding_layer = Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable = False)\n",
        "  inputs = Input(shape=(maxlen,))\n",
        "  embedding = embedding_layer(inputs)\n",
        "\n",
        "  reshape = Reshape((maxlen,embedding_dim,1))(embedding)\n",
        "\n",
        "  conv_0 = Conv2D(num_filters, kernel_size=(3, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu' , kernel_regularizer='l2')(reshape)\n",
        "  conv_1 = Conv2D(num_filters, kernel_size=(4, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer='l2')(reshape)\n",
        "  conv_2 = Conv2D(num_filters, kernel_size=(5, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer='l2')(reshape)\n",
        "\n",
        "  maxpool_0 = MaxPool2D(pool_size=(maxlen - 3 + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
        "  maxpool_1 = MaxPool2D(pool_size=(maxlen - 4 + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
        "  maxpool_2 = MaxPool2D(pool_size=(maxlen - 5 + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
        "\n",
        "  concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
        "  flatten = Flatten()(concatenated_tensor)\n",
        "  dropout = Dropout(0.5)(flatten)\n",
        "  output = Dense(1, activation='sigmoid', kernel_regularizer='l2')(dropout)\n",
        "\n",
        "  # this creates a model that includes\n",
        "  model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "  model.compile(loss ='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRQ2FrxJqRdP"
      },
      "source": [
        "tune_model = KerasClassifier(build_fn = create_model, epochs=30, batch_size=20, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6ELBRDQqSSH",
        "outputId": "4ffcae92-774a-4218-d65e-839929ea309a"
      },
      "source": [
        "# grid search hyperparameter tunnig\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "param_grid = dict(optimizer=optimizer)\n",
        "grid = GridSearchCV(estimator=tune_model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "Best: 0.787801 using {'optimizer': 'SGD'}\n",
            "0.787801 (0.007704) with: {'optimizer': 'SGD'}\n",
            "0.771577 (0.009763) with: {'optimizer': 'RMSprop'}\n",
            "0.772551 (0.007782) with: {'optimizer': 'Adagrad'}\n",
            "0.704578 (0.013260) with: {'optimizer': 'Adadelta'}\n",
            "0.769793 (0.009609) with: {'optimizer': 'Adam'}\n",
            "0.779527 (0.007203) with: {'optimizer': 'Adamax'}\n",
            "0.777256 (0.011834) with: {'optimizer': 'Nadam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah0ZBkFWq7WC"
      },
      "source": [
        "**learning rate & momentum** : 'learn_rate': 0.01, 'momentum': 0.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxdGtzL6rGsq"
      },
      "source": [
        "\n",
        "def create_model(learn_rate=0.01, momentum=0):\n",
        "  num_filters = 128\n",
        "\n",
        "  Embedding_layer = Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable = False)\n",
        "\n",
        "  input = Input(shape=(maxlen,))\n",
        "  embedding = Embedding_layer(input)\n",
        "\n",
        "  reshape = Reshape((maxlen,embedding_dim,1))(embedding)\n",
        "\n",
        "  conv1 = Conv2D(num_filters, kernel_size=(3, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu' , kernel_regularizer='l2')(reshape)\n",
        "  conv2 = Conv2D(num_filters, kernel_size=(4, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer='l2')(reshape)\n",
        "  conv3 = Conv2D(num_filters, kernel_size=(5, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer='l2')(reshape)\n",
        "\n",
        "  maxpooling1 = MaxPool2D(pool_size=(maxlen - 3 + 1, 1), strides=(1,1), padding='valid')(conv1)\n",
        "  maxpooling2 = MaxPool2D(pool_size=(maxlen - 4 + 1, 1), strides=(1,1), padding='valid')(conv2)\n",
        "  maxpooling3 = MaxPool2D(pool_size=(maxlen - 5 + 1, 1), strides=(1,1), padding='valid')(conv3)\n",
        "\n",
        "  concatenated_tensor = Concatenate(axis=1)([maxpooling1, maxpooling2, maxpooling3])\n",
        "  flatten = Flatten()(concatenated_tensor)\n",
        "  dropout = Dropout(0.5)(flatten)\n",
        "  output_layer = Dense(1, activation='sigmoid', kernel_regularizer='l2')(dropout)\n",
        "\n",
        "  # this creates a model that includes\n",
        "  model = Model(inputs=input, outputs=output_layer)\n",
        "\n",
        "  opt = keras.optimizers.SGD(lr=learn_rate, momentum=momentum)\n",
        "  model.compile(loss ='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCnxUX57TBuM",
        "outputId": "ed51e5bf-740e-4ba1-d821-1165b78b1749"
      },
      "source": [
        "tune_model = KerasClassifier(build_fn = create_model, epochs=30, batch_size=20, verbose=0)\n",
        "\n",
        "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
        "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "\n",
        "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
        "grid = GridSearchCV(estimator=tune_model, param_grid=param_grid, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "(None, 100, 100)\n",
            "(None, 100, 100, 1)\n",
            "Best: 0.787962 using {'learn_rate': 0.01, 'momentum': 0.4}\n",
            "0.762655 (0.004220) with: {'learn_rate': 0.001, 'momentum': 0.0}\n",
            "0.761681 (0.002652) with: {'learn_rate': 0.001, 'momentum': 0.2}\n",
            "0.767034 (0.003362) with: {'learn_rate': 0.001, 'momentum': 0.4}\n",
            "0.773523 (0.007381) with: {'learn_rate': 0.001, 'momentum': 0.6}\n",
            "0.777254 (0.006272) with: {'learn_rate': 0.001, 'momentum': 0.8}\n",
            "0.782933 (0.001987) with: {'learn_rate': 0.001, 'momentum': 0.9}\n",
            "0.776931 (0.001559) with: {'learn_rate': 0.01, 'momentum': 0.0}\n",
            "0.784719 (0.005825) with: {'learn_rate': 0.01, 'momentum': 0.2}\n",
            "0.787962 (0.002977) with: {'learn_rate': 0.01, 'momentum': 0.4}\n",
            "0.775795 (0.001669) with: {'learn_rate': 0.01, 'momentum': 0.6}\n",
            "0.773846 (0.011624) with: {'learn_rate': 0.01, 'momentum': 0.8}\n",
            "0.760385 (0.010992) with: {'learn_rate': 0.01, 'momentum': 0.9}\n",
            "0.778067 (0.001773) with: {'learn_rate': 0.1, 'momentum': 0.0}\n",
            "0.755195 (0.016475) with: {'learn_rate': 0.1, 'momentum': 0.2}\n",
            "0.770116 (0.005867) with: {'learn_rate': 0.1, 'momentum': 0.4}\n",
            "0.718847 (0.039507) with: {'learn_rate': 0.1, 'momentum': 0.6}\n",
            "0.590040 (0.005088) with: {'learn_rate': 0.1, 'momentum': 0.8}\n",
            "0.590040 (0.005088) with: {'learn_rate': 0.1, 'momentum': 0.9}\n",
            "0.639699 (0.095127) with: {'learn_rate': 0.2, 'momentum': 0.0}\n",
            "0.744968 (0.014001) with: {'learn_rate': 0.2, 'momentum': 0.2}\n",
            "0.740107 (0.015511) with: {'learn_rate': 0.2, 'momentum': 0.4}\n",
            "0.660613 (0.029787) with: {'learn_rate': 0.2, 'momentum': 0.6}\n",
            "0.590040 (0.005088) with: {'learn_rate': 0.2, 'momentum': 0.8}\n",
            "0.590040 (0.005088) with: {'learn_rate': 0.2, 'momentum': 0.9}\n",
            "0.749030 (0.016904) with: {'learn_rate': 0.3, 'momentum': 0.0}\n",
            "0.690954 (0.055092) with: {'learn_rate': 0.3, 'momentum': 0.2}\n",
            "0.672297 (0.062533) with: {'learn_rate': 0.3, 'momentum': 0.4}\n",
            "0.590040 (0.005088) with: {'learn_rate': 0.3, 'momentum': 0.6}\n",
            "0.590040 (0.005088) with: {'learn_rate': 0.3, 'momentum': 0.8}\n",
            "0.590040 (0.005088) with: {'learn_rate': 0.3, 'momentum': 0.9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNBsgcVnrHC3"
      },
      "source": [
        "**dropout regularization** : 0.6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x7SyXpvrJTj"
      },
      "source": [
        "def create_model(dropout_rate=0.0):\n",
        "  num_filters = 128\n",
        "\n",
        "  Embedding_layer = Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable = False)\n",
        "\n",
        "  input = Input(shape=(maxlen,))\n",
        "  embedding = Embedding_layer(input)\n",
        "\n",
        "  reshape = Reshape((maxlen,embedding_dim,1))(embedding)\n",
        "\n",
        "  conv1 = Conv2D(num_filters, kernel_size=(3, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu' , kernel_regularizer='l2')(reshape)\n",
        "  conv2 = Conv2D(num_filters, kernel_size=(4, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer='l2')(reshape)\n",
        "  conv3 = Conv2D(num_filters, kernel_size=(5, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer='l2')(reshape)\n",
        "\n",
        "  maxpooling1 = MaxPool2D(pool_size=(maxlen - 3 + 1, 1), strides=(1,1), padding='valid')(conv1)\n",
        "  maxpooling2 = MaxPool2D(pool_size=(maxlen - 4 + 1, 1), strides=(1,1), padding='valid')(conv2)\n",
        "  maxpooling3 = MaxPool2D(pool_size=(maxlen - 5 + 1, 1), strides=(1,1), padding='valid')(conv3)\n",
        "\n",
        "  concatenated_tensor = Concatenate(axis=1)([maxpooling1, maxpooling2, maxpooling3])\n",
        "  flatten = Flatten()(concatenated_tensor)\n",
        "  dropout = Dropout(dropout_rate)(flatten)\n",
        "  output_layer = Dense(1, activation='sigmoid', kernel_regularizer='l2')(dropout)\n",
        "\n",
        "  # this creates a model that includes\n",
        "  model = Model(inputs=input, outputs=output_layer)\n",
        "\n",
        "  opt = keras.optimizers.SGD(lr=0.01, momentum=0.4)\n",
        "  model.compile(loss ='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38oZcGcBT6YA",
        "outputId": "f9cc10bd-dc0d-46cd-e3cc-a0b43d4a7374"
      },
      "source": [
        "tune_model = KerasClassifier(build_fn = create_model, epochs=30, batch_size=20, verbose=0)\n",
        "\n",
        "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "param_grid = dict(dropout_rate = dropout_rate)\n",
        "grid = GridSearchCV(estimator=tune_model, param_grid=param_grid, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.790233 using {'dropout_rate': 0.6}\n",
            "0.782285 (0.004869) with: {'dropout_rate': 0.0}\n",
            "0.785041 (0.005342) with: {'dropout_rate': 0.1}\n",
            "0.786016 (0.010133) with: {'dropout_rate': 0.2}\n",
            "0.786015 (0.002674) with: {'dropout_rate': 0.3}\n",
            "0.763631 (0.021347) with: {'dropout_rate': 0.4}\n",
            "0.783582 (0.001205) with: {'dropout_rate': 0.5}\n",
            "0.790233 (0.003579) with: {'dropout_rate': 0.6}\n",
            "0.786341 (0.002819) with: {'dropout_rate': 0.7}\n",
            "0.777253 (0.009020) with: {'dropout_rate': 0.8}\n",
            "0.779040 (0.003763) with: {'dropout_rate': 0.9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25OO7IwIfqF2"
      },
      "source": [
        "l1 vs l2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkATlVP_fr66"
      },
      "source": [
        "def create_model(reg = 'l1'):\n",
        "  num_filters = 128\n",
        "\n",
        "  Embedding_layer = Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable = False)\n",
        "\n",
        "  input = Input(shape=(maxlen,))\n",
        "  embedding = Embedding_layer(input)\n",
        "\n",
        "  reshape = Reshape((maxlen,embedding_dim,1))(embedding)\n",
        "\n",
        "  conv1 = Conv2D(num_filters, kernel_size=(3, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu' , kernel_regularizer=reg)(reshape)\n",
        "  conv2 = Conv2D(num_filters, kernel_size=(4, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer=reg)(reshape)\n",
        "  conv3 = Conv2D(num_filters, kernel_size=(5, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer=reg)(reshape)\n",
        "\n",
        "  maxpooling1 = MaxPool2D(pool_size=(maxlen - 3 + 1, 1), strides=(1,1), padding='valid')(conv1)\n",
        "  maxpooling2 = MaxPool2D(pool_size=(maxlen - 4 + 1, 1), strides=(1,1), padding='valid')(conv2)\n",
        "  maxpooling3 = MaxPool2D(pool_size=(maxlen - 5 + 1, 1), strides=(1,1), padding='valid')(conv3)\n",
        "\n",
        "  concatenated_tensor = Concatenate(axis=1)([maxpooling1, maxpooling2, maxpooling3])\n",
        "  flatten = Flatten()(concatenated_tensor)\n",
        "  dropout = Dropout(0.6)(flatten)\n",
        "  output_layer = Dense(1, activation='sigmoid', kernel_regularizer=reg)(dropout)\n",
        "\n",
        "  # this creates a model that includes\n",
        "  model = Model(inputs=input, outputs=output_layer)\n",
        "\n",
        "  opt = keras.optimizers.SGD(lr= 0.01, momentum=0.4)\n",
        "  model.compile(loss ='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0xSyv_4ftrA",
        "outputId": "d06cd773-fcaa-4a50-8fac-b6540fcf86e4"
      },
      "source": [
        "tune_model = KerasClassifier(build_fn = create_model, epochs=30, batch_size=20, verbose=0)\n",
        "\n",
        "reg = ['l1','l2']\n",
        "\n",
        "param_grid = dict(reg = reg)\n",
        "grid = GridSearchCV(estimator=tune_model, param_grid=param_grid, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.780336 using {'reg': 'l2'}\n",
            "0.590040 (0.005088) with: {'reg': 'l1'}\n",
            "0.780336 (0.007414) with: {'reg': 'l2'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqnt-C7pfeW_"
      },
      "source": [
        "#final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6-riVXTi2EY"
      },
      "source": [
        "\n",
        "def create_model():\n",
        "  num_filters = 128\n",
        "  reg = 'l2'\n",
        "\n",
        "  Embedding_layer = Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable = False)\n",
        "\n",
        "  input = Input(shape=(maxlen,))\n",
        "  embedding = Embedding_layer(input)\n",
        "\n",
        "  reshape = Reshape((maxlen,embedding_dim,1))(embedding)\n",
        "\n",
        "  conv1 = Conv2D(num_filters, kernel_size=(3, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu' , kernel_regularizer=reg)(reshape)\n",
        "  conv2 = Conv2D(num_filters, kernel_size=(4, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer=reg)(reshape)\n",
        "  conv3 = Conv2D(num_filters, kernel_size=(5, embedding_dim), \n",
        "                padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer=reg)(reshape)\n",
        "\n",
        "  maxpooling1 = MaxPool2D(pool_size=(maxlen - 3 + 1, 1), strides=(1,1), padding='valid')(conv1)\n",
        "  maxpooling2 = MaxPool2D(pool_size=(maxlen - 4 + 1, 1), strides=(1,1), padding='valid')(conv2)\n",
        "  maxpooling3 = MaxPool2D(pool_size=(maxlen - 5 + 1, 1), strides=(1,1), padding='valid')(conv3)\n",
        "\n",
        "  concatenated_tensor = Concatenate(axis=1)([maxpooling1, maxpooling2, maxpooling3])\n",
        "  flatten = Flatten()(concatenated_tensor)\n",
        "  dropout = Dropout(0.6)(flatten)\n",
        "  output_layer = Dense(1, activation='sigmoid', kernel_regularizer=reg)(dropout)\n",
        "\n",
        "  # this creates a model that includes\n",
        "  model = Model(inputs=input, outputs=output_layer)\n",
        "\n",
        "  opt = keras.optimizers.SGD(lr= 0.01, momentum=0.4)\n",
        "  model.compile(loss ='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdEGHkxnjAxL"
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XQnMnKhjDXB",
        "outputId": "254bfe36-f0cd-461e-bedd-f0d38cf090ec"
      },
      "source": [
        "callback = [keras.callbacks.ModelCheckpoint(filepath='best.h5', monitor='val_loss', mode='min', save_best_only=True),\n",
        "            keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto',baseline=None, restore_best_weights=False)]\n",
        "\n",
        "# history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=20, shuffle=True, callbacks=callback)\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=20, shuffle=True, callbacks=callback)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "247/247 [==============================] - 2s 6ms/step - loss: 4.2607 - accuracy: 0.6277 - val_loss: 3.8477 - val_accuracy: 0.7153\n",
            "Epoch 2/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 3.6013 - accuracy: 0.7059 - val_loss: 3.3267 - val_accuracy: 0.7356\n",
            "Epoch 3/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 3.1130 - accuracy: 0.7374 - val_loss: 2.8775 - val_accuracy: 0.7648\n",
            "Epoch 4/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 2.7023 - accuracy: 0.7548 - val_loss: 2.5124 - val_accuracy: 0.7616\n",
            "Epoch 5/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 2.3675 - accuracy: 0.7597 - val_loss: 2.2120 - val_accuracy: 0.7632\n",
            "Epoch 6/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 2.0776 - accuracy: 0.7698 - val_loss: 1.9532 - val_accuracy: 0.7648\n",
            "Epoch 7/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 1.8308 - accuracy: 0.7828 - val_loss: 1.7422 - val_accuracy: 0.7648\n",
            "Epoch 8/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 1.6279 - accuracy: 0.7848 - val_loss: 1.5490 - val_accuracy: 0.7737\n",
            "Epoch 9/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 1.4480 - accuracy: 0.7917 - val_loss: 1.3915 - val_accuracy: 0.7689\n",
            "Epoch 10/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 1.3027 - accuracy: 0.7954 - val_loss: 1.2619 - val_accuracy: 0.7802\n",
            "Epoch 11/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 1.1774 - accuracy: 0.8041 - val_loss: 1.1497 - val_accuracy: 0.7745\n",
            "Epoch 12/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 1.0724 - accuracy: 0.8073 - val_loss: 1.0610 - val_accuracy: 0.7753\n",
            "Epoch 13/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 0.9834 - accuracy: 0.8122 - val_loss: 0.9819 - val_accuracy: 0.7810\n",
            "Epoch 14/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.9057 - accuracy: 0.8148 - val_loss: 0.9131 - val_accuracy: 0.7810\n",
            "Epoch 15/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.8394 - accuracy: 0.8213 - val_loss: 0.8557 - val_accuracy: 0.7770\n",
            "Epoch 16/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 0.7872 - accuracy: 0.8193 - val_loss: 0.8142 - val_accuracy: 0.7826\n",
            "Epoch 17/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.7410 - accuracy: 0.8242 - val_loss: 0.7730 - val_accuracy: 0.7794\n",
            "Epoch 18/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.6970 - accuracy: 0.8321 - val_loss: 0.7367 - val_accuracy: 0.7835\n",
            "Epoch 19/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.6694 - accuracy: 0.8276 - val_loss: 0.7097 - val_accuracy: 0.7843\n",
            "Epoch 20/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 0.6429 - accuracy: 0.8337 - val_loss: 0.6856 - val_accuracy: 0.7851\n",
            "Epoch 21/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 0.6200 - accuracy: 0.8363 - val_loss: 0.6680 - val_accuracy: 0.7843\n",
            "Epoch 22/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 0.6013 - accuracy: 0.8343 - val_loss: 0.6515 - val_accuracy: 0.7826\n",
            "Epoch 23/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.5839 - accuracy: 0.8311 - val_loss: 0.6388 - val_accuracy: 0.7818\n",
            "Epoch 24/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 0.5674 - accuracy: 0.8404 - val_loss: 0.6273 - val_accuracy: 0.7891\n",
            "Epoch 25/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 0.5569 - accuracy: 0.8363 - val_loss: 0.6218 - val_accuracy: 0.7875\n",
            "Epoch 26/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 0.5482 - accuracy: 0.8390 - val_loss: 0.6188 - val_accuracy: 0.7891\n",
            "Epoch 27/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 0.5413 - accuracy: 0.8349 - val_loss: 0.6045 - val_accuracy: 0.7875\n",
            "Epoch 28/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.5341 - accuracy: 0.8408 - val_loss: 0.5981 - val_accuracy: 0.7908\n",
            "Epoch 29/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.5253 - accuracy: 0.8398 - val_loss: 0.5959 - val_accuracy: 0.7835\n",
            "Epoch 30/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.5177 - accuracy: 0.8481 - val_loss: 0.5914 - val_accuracy: 0.7924\n",
            "Epoch 31/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.5173 - accuracy: 0.8420 - val_loss: 0.5896 - val_accuracy: 0.7883\n",
            "Epoch 32/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.5091 - accuracy: 0.8479 - val_loss: 0.5854 - val_accuracy: 0.7916\n",
            "Epoch 33/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.5098 - accuracy: 0.8467 - val_loss: 0.5884 - val_accuracy: 0.7851\n",
            "Epoch 34/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 0.5050 - accuracy: 0.8499 - val_loss: 0.5856 - val_accuracy: 0.7883\n",
            "Epoch 35/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 0.5014 - accuracy: 0.8449 - val_loss: 0.5818 - val_accuracy: 0.7908\n",
            "Epoch 36/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.4998 - accuracy: 0.8459 - val_loss: 0.5871 - val_accuracy: 0.7908\n",
            "Epoch 37/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.4983 - accuracy: 0.8473 - val_loss: 0.5832 - val_accuracy: 0.7908\n",
            "Epoch 38/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.4949 - accuracy: 0.8495 - val_loss: 0.6040 - val_accuracy: 0.7737\n",
            "Epoch 39/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.4939 - accuracy: 0.8560 - val_loss: 0.5801 - val_accuracy: 0.7891\n",
            "Epoch 40/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.4936 - accuracy: 0.8538 - val_loss: 0.5861 - val_accuracy: 0.7859\n",
            "Epoch 41/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.4935 - accuracy: 0.8491 - val_loss: 0.5789 - val_accuracy: 0.7908\n",
            "Epoch 42/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.4904 - accuracy: 0.8526 - val_loss: 0.6112 - val_accuracy: 0.7656\n",
            "Epoch 43/100\n",
            "247/247 [==============================] - 1s 5ms/step - loss: 0.4927 - accuracy: 0.8538 - val_loss: 0.5799 - val_accuracy: 0.7908\n",
            "Epoch 44/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.4869 - accuracy: 0.8564 - val_loss: 0.5839 - val_accuracy: 0.7826\n",
            "Epoch 45/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.4882 - accuracy: 0.8520 - val_loss: 0.5845 - val_accuracy: 0.7908\n",
            "Epoch 46/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.4859 - accuracy: 0.8633 - val_loss: 0.5908 - val_accuracy: 0.7899\n",
            "Epoch 47/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.4846 - accuracy: 0.8617 - val_loss: 0.5840 - val_accuracy: 0.7932\n",
            "Epoch 48/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.4842 - accuracy: 0.8586 - val_loss: 0.5878 - val_accuracy: 0.7924\n",
            "Epoch 49/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.4835 - accuracy: 0.8599 - val_loss: 0.5857 - val_accuracy: 0.7916\n",
            "Epoch 50/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.4805 - accuracy: 0.8623 - val_loss: 0.5814 - val_accuracy: 0.7875\n",
            "Epoch 51/100\n",
            "247/247 [==============================] - 1s 4ms/step - loss: 0.4855 - accuracy: 0.8619 - val_loss: 0.5889 - val_accuracy: 0.7835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "971FD-aSuj6N",
        "outputId": "67ef55b6-59f2-41d1-d777-305cf5b2cee3"
      },
      "source": [
        "# load a saved model\n",
        "saved_model = load_model('best.h5')\n",
        "saved_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.7956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5744956135749817, 0.7956204414367676]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh5PHFENldDg"
      },
      "source": [
        "#LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz_xMeBmlfU2",
        "outputId": "ff2ce52b-eb91-49bd-d133-8005366f0488"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "model_save_folder_path = '/content/gdrive/My Drive/AI Lecture/'\n",
        "if not os.path.exists(model_save_folder_path):\n",
        "  os.mkdir(model_save_folder_path)\n",
        "model_path = model_save_folder_path + 'best_lstm.hdf5'\n",
        "modelckpt = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model_1 = Sequential()\n",
        "model_1.add(Embedding(max_words, 100))\n",
        "model_1.add(LSTM(32))\n",
        "model_1.add(Dropout(0.2))\n",
        "model_1.add(Dense(1, activation='sigmoid'))\n",
        "model_1.summary()\n",
        "model_1.layers[0].set_weights([embedding_matrix])\n",
        "model_1.layers[0].trainable = False\n",
        "model_1.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model_1.fit(X_train, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[modelckpt])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 100)         1000000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,017,057\n",
            "Trainable params: 1,017,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.6824 - acc: 0.5904\n",
            "Epoch 00001: val_loss improved from inf to 0.66005, saving model to /content/gdrive/My Drive/AI Lecture/best_lstm.hdf5\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.6800 - acc: 0.5935 - val_loss: 0.6601 - val_acc: 0.5543\n",
            "Epoch 2/20\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.6191 - acc: 0.6218\n",
            "Epoch 00002: val_loss improved from 0.66005 to 0.61539, saving model to /content/gdrive/My Drive/AI Lecture/best_lstm.hdf5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.6180 - acc: 0.6265 - val_loss: 0.6154 - val_acc: 0.7423\n",
            "Epoch 3/20\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.5854 - acc: 0.7237\n",
            "Epoch 00003: val_loss improved from 0.61539 to 0.58161, saving model to /content/gdrive/My Drive/AI Lecture/best_lstm.hdf5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.5849 - acc: 0.7242 - val_loss: 0.5816 - val_acc: 0.7553\n",
            "Epoch 4/20\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.5668 - acc: 0.7366\n",
            "Epoch 00004: val_loss improved from 0.58161 to 0.55147, saving model to /content/gdrive/My Drive/AI Lecture/best_lstm.hdf5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.5675 - acc: 0.7364 - val_loss: 0.5515 - val_acc: 0.7731\n",
            "Epoch 5/20\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.5482 - acc: 0.7591\n",
            "Epoch 00005: val_loss improved from 0.55147 to 0.51613, saving model to /content/gdrive/My Drive/AI Lecture/best_lstm.hdf5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.5460 - acc: 0.7615 - val_loss: 0.5161 - val_acc: 0.7796\n",
            "Epoch 6/20\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.5370 - acc: 0.7678\n",
            "Epoch 00006: val_loss did not improve from 0.51613\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.5391 - acc: 0.7667 - val_loss: 0.5259 - val_acc: 0.7780\n",
            "Epoch 7/20\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.5259 - acc: 0.7676\n",
            "Epoch 00007: val_loss did not improve from 0.51613\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.5264 - acc: 0.7671 - val_loss: 0.5537 - val_acc: 0.7585\n",
            "Epoch 8/20\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.5097 - acc: 0.7811\n",
            "Epoch 00008: val_loss improved from 0.51613 to 0.51324, saving model to /content/gdrive/My Drive/AI Lecture/best_lstm.hdf5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.5090 - acc: 0.7813 - val_loss: 0.5132 - val_acc: 0.7666\n",
            "Epoch 9/20\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.4997 - acc: 0.7789\n",
            "Epoch 00009: val_loss improved from 0.51324 to 0.47265, saving model to /content/gdrive/My Drive/AI Lecture/best_lstm.hdf5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.5005 - acc: 0.7784 - val_loss: 0.4727 - val_acc: 0.8055\n",
            "Epoch 10/20\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.4992 - acc: 0.7803\n",
            "Epoch 00010: val_loss did not improve from 0.47265\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.4988 - acc: 0.7806 - val_loss: 0.5188 - val_acc: 0.7407\n",
            "Epoch 11/20\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.4901 - acc: 0.7876\n",
            "Epoch 00011: val_loss improved from 0.47265 to 0.47262, saving model to /content/gdrive/My Drive/AI Lecture/best_lstm.hdf5\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 0.4922 - acc: 0.7862 - val_loss: 0.4726 - val_acc: 0.7958\n",
            "Epoch 12/20\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.4797 - acc: 0.7971\n",
            "Epoch 00012: val_loss did not improve from 0.47262\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.4830 - acc: 0.7945 - val_loss: 0.5219 - val_acc: 0.7293\n",
            "Epoch 13/20\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.4766 - acc: 0.7991\n",
            "Epoch 00013: val_loss did not improve from 0.47262\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.4783 - acc: 0.7984 - val_loss: 0.4767 - val_acc: 0.7893\n",
            "Epoch 14/20\n",
            "40/44 [==========================>...] - ETA: 0s - loss: 0.4659 - acc: 0.8035\n",
            "Epoch 00014: val_loss improved from 0.47262 to 0.46373, saving model to /content/gdrive/My Drive/AI Lecture/best_lstm.hdf5\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.4672 - acc: 0.8031 - val_loss: 0.4637 - val_acc: 0.8023\n",
            "Epoch 15/20\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.4705 - acc: 0.8007\n",
            "Epoch 00015: val_loss improved from 0.46373 to 0.46319, saving model to /content/gdrive/My Drive/AI Lecture/best_lstm.hdf5\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.4704 - acc: 0.8006 - val_loss: 0.4632 - val_acc: 0.8006\n",
            "Epoch 16/20\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.4603 - acc: 0.8069\n",
            "Epoch 00016: val_loss did not improve from 0.46319\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.4624 - acc: 0.8057 - val_loss: 0.5679 - val_acc: 0.7229\n",
            "Epoch 17/20\n",
            "42/44 [===========================>..] - ETA: 0s - loss: 0.4556 - acc: 0.8132\n",
            "Epoch 00017: val_loss did not improve from 0.46319\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.4560 - acc: 0.8136 - val_loss: 0.4687 - val_acc: 0.7942\n",
            "Epoch 18/20\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 0.4525 - acc: 0.8089\n",
            "Epoch 00018: val_loss did not improve from 0.46319\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.4532 - acc: 0.8091 - val_loss: 0.5011 - val_acc: 0.7780\n",
            "Epoch 19/20\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.4530 - acc: 0.8143\n",
            "Epoch 00019: val_loss did not improve from 0.46319\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 0.4533 - acc: 0.8138 - val_loss: 0.4706 - val_acc: 0.7942\n",
            "Epoch 20/20\n",
            "43/44 [============================>.] - ETA: 0s - loss: 0.4393 - acc: 0.8245\n",
            "Epoch 00020: val_loss did not improve from 0.46319\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 0.4408 - acc: 0.8235 - val_loss: 0.5090 - val_acc: 0.7796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh67_mf5VFop"
      },
      "source": [
        "#SVM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96T0d6lUVIHG",
        "outputId": "197b38a1-96fb-4df2-8e84-d362eb7f6593"
      },
      "source": [
        "sv = svm.SVC()\n",
        "sv.fit(X_train, y_train)\n",
        "\n",
        "pred= sv.predict(X_test)\n",
        "# print(\"svm accuracy -> \", accuracy_score(pred, y_test)*100)\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "svm accuracy ->  58.68613138686132\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.59      0.96      0.73       406\n",
            "         1.0       0.42      0.04      0.07       279\n",
            "\n",
            "    accuracy                           0.59       685\n",
            "   macro avg       0.51      0.50      0.40       685\n",
            "weighted avg       0.52      0.59      0.46       685\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p-wXCUDvJ9S",
        "outputId": "41f358cf-dd3b-460a-d8a5-aa371158265e"
      },
      "source": [
        "#hyperparameter tuning\n",
        "sv = svm.SVC(kernel='RBF')\n",
        "\n",
        "kernel = ['poly', 'rbf', 'sigmoid']\n",
        "\n",
        "param_grid = {'kernel': kernel}\n",
        "  \n",
        "grid = GridSearchCV(sv, param_grid, refit = True, verbose = 3) \n",
        "grid.fit(X_train, y_train) \n",
        "\n",
        "print(grid.best_params_) \n",
        "#print tuned model\n",
        "print(grid.best_estimator_) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
            "[CV] kernel=poly .....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......................... kernel=poly, score=0.590, total=   5.1s\n",
            "[CV] kernel=poly .....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......................... kernel=poly, score=0.588, total=   4.9s\n",
            "[CV] kernel=poly .....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   10.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......................... kernel=poly, score=0.581, total=   4.7s\n",
            "[CV] kernel=poly .....................................................\n",
            "[CV] ......................... kernel=poly, score=0.579, total=   4.7s\n",
            "[CV] kernel=poly .....................................................\n",
            "[CV] ......................... kernel=poly, score=0.572, total=   4.5s\n",
            "[CV] kernel=rbf ......................................................\n",
            "[CV] .......................... kernel=rbf, score=0.596, total=   4.7s\n",
            "[CV] kernel=rbf ......................................................\n",
            "[CV] .......................... kernel=rbf, score=0.591, total=   4.7s\n",
            "[CV] kernel=rbf ......................................................\n",
            "[CV] .......................... kernel=rbf, score=0.577, total=   4.8s\n",
            "[CV] kernel=rbf ......................................................\n",
            "[CV] .......................... kernel=rbf, score=0.586, total=   4.8s\n",
            "[CV] kernel=rbf ......................................................\n",
            "[CV] .......................... kernel=rbf, score=0.587, total=   4.9s\n",
            "[CV] kernel=sigmoid ..................................................\n",
            "[CV] ...................... kernel=sigmoid, score=0.479, total=   3.4s\n",
            "[CV] kernel=sigmoid ..................................................\n",
            "[CV] ...................... kernel=sigmoid, score=0.487, total=   5.0s\n",
            "[CV] kernel=sigmoid ..................................................\n",
            "[CV] ...................... kernel=sigmoid, score=0.502, total=   3.1s\n",
            "[CV] kernel=sigmoid ..................................................\n",
            "[CV] ...................... kernel=sigmoid, score=0.483, total=   3.2s\n",
            "[CV] kernel=sigmoid ..................................................\n",
            "[CV] ...................... kernel=sigmoid, score=0.466, total=   3.5s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'kernel': 'rbf'}\n",
            "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VvHHV-qVzp_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae6085b-2a54-444c-efa7-e00c439b618d"
      },
      "source": [
        "#hyperparameter tuning\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
        "              'kernel': ['rbf']}  \n",
        "  \n",
        "grid = GridSearchCV(svm, param_grid, refit = True, verbose = 3) \n",
        "grid.fit(X_train, y_train) \n",
        "\n",
        "\n",
        "print(grid.best_params_) \n",
        "  \n",
        "print(grid.best_estimator_) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.592, total=   4.8s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.592, total=   4.8s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    9.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.592, total=   4.8s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.592, total=   4.8s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.593, total=   4.8s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.592, total=   4.8s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.592, total=   4.8s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.592, total=   4.8s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.593, total=   4.8s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.592, total=   4.8s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.592, total=   4.6s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.593, total=   4.7s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.593, total=   4.6s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.593, total=   4.7s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.594, total=   4.6s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.594, total=   4.7s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.593, total=   4.7s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.590, total=   4.7s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.593, total=   4.6s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.594, total=   4.6s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.593, total=   4.6s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.593, total=   4.7s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.591, total=   4.7s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.594, total=   4.7s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.594, total=   4.6s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.593, total=   4.6s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.594, total=   4.7s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.591, total=   4.6s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.593, total=   4.6s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.594, total=   4.6s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.599, total=   4.6s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.598, total=   4.6s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.594, total=   4.6s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.595, total=   4.7s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.595, total=   4.7s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.604, total=   4.7s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.594, total=   4.7s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.594, total=   4.7s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.595, total=   4.7s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.594, total=   4.8s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.594, total=   4.7s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.593, total=   4.7s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.590, total=   4.8s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.593, total=   4.8s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.592, total=   4.8s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.592, total=   4.8s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.593, total=   4.8s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.590, total=   4.8s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.594, total=   4.8s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.594, total=   4.8s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.595, total=   4.9s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.595, total=   4.7s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.590, total=   4.8s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.594, total=   4.8s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.590, total=   4.7s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.599, total=   4.7s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.596, total=   4.7s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.594, total=   4.6s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.590, total=   4.7s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.602, total=   4.8s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.590, total=   4.8s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.593, total=   4.7s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.594, total=   4.8s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.594, total=   4.6s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.594, total=   4.6s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.593, total=   4.6s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.590, total=   4.7s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.593, total=   4.8s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.593, total=   4.6s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.590, total=   4.6s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.594, total=   4.7s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.594, total=   4.7s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.594, total=   4.6s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.595, total=   4.6s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.590, total=   4.6s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.594, total=   4.6s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.589, total=   4.6s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.599, total=   4.6s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.596, total=   4.7s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.592, total=   4.6s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.594, total=   5.2s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.591, total=   4.8s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.604, total=   4.8s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.590, total=   4.7s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.589, total=   4.7s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.593, total=   4.7s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.594, total=   4.6s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.594, total=   4.7s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.593, total=   4.6s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.590, total=   4.6s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.593, total=   4.6s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.592, total=   4.7s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.593, total=   4.6s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.590, total=   4.6s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.594, total=   4.7s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.594, total=   4.6s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.594, total=   4.5s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.595, total=   4.6s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.590, total=   4.6s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.594, total=   4.6s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.589, total=   4.6s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.599, total=   4.6s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.596, total=   5.2s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.590, total=   4.6s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.594, total=   6.6s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.589, total=   4.7s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.602, total=   4.8s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.589, total=   4.8s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.589, total=   4.8s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.593, total=   4.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:  9.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKh7a4WkAiDA",
        "outputId": "1d9c7242-b634-4231-af50-0f14d6f7f971"
      },
      "source": [
        "sv = svm.SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
        "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
        "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
        "    tol=0.001, verbose=False)\n",
        "\n",
        "sv.fit(X_train, y_train)\n",
        "\n",
        "pred= sv.predict(X_test)\n",
        "print(\"svm accuracy -> \", accuracy_score(pred, y_test)*100)\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "svm accuracy ->  59.70802919708029\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      1.00      0.75       407\n",
            "         1.0       0.67      0.01      0.03       278\n",
            "\n",
            "    accuracy                           0.60       685\n",
            "   macro avg       0.63      0.50      0.39       685\n",
            "weighted avg       0.62      0.60      0.45       685\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opl2nYs-E3J_"
      },
      "source": [
        "save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df2q_rPUBINg"
      },
      "source": [
        "filename = '/content/gdrive/My Drive/AI Lecture/best_svm.sav'\n",
        "pickle.dump(sv, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAM5sHBfB2oQ"
      },
      "source": [
        "kn = KNeighborsClassifier(n_neighbors=21)\n",
        "kn.fit(X_train, y_train)\n",
        "\n",
        "filename = '/content/gdrive/My Drive/AI Lecture/best_knn.sav'\n",
        "pickle.dump(sv, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GVN-rHL9Sik"
      },
      "source": [
        "#KNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHgvgUzp9RfV"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "training_accuracy = []\n",
        "test_accuracy = []\n",
        "neighbors_settings = range(1, 30)\n",
        "\n",
        "for n_neighbors in neighbors_settings:\n",
        "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    clf.fit(X_train, y_train)\n",
        "    training_accuracy.append(clf.score(X_train, y_train))\n",
        "    test_accuracy.append(clf.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzmdfX-p9iZ1"
      },
      "source": [
        "test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ4Q6DOr9mnT"
      },
      "source": [
        "test_accuracy .index(max(test_accuracy ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz9ckKLKko-H"
      },
      "source": [
        "#Model ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIHxm-MkksFP"
      },
      "source": [
        "cnn_model = load_model('/content/gdrive/My Drive/AI Lecture/best_cnn.h5')\n",
        "lstm_model = load_model('/content/gdrive/My Drive/AI Lecture/best_lstm.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtcPomtR02IR"
      },
      "source": [
        "majority voting ensemble (hard voting) \n",
        "\n",
        " *-> not performing any better!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrhz7_H5uCrn"
      },
      "source": [
        "def get_pred(model):\n",
        "  pred_prob = saved_model.predict(X_test)\n",
        "  pred_prob = pred_prob[:, 0]\n",
        "  pred_class = []\n",
        "  for i in pred_prob:\n",
        "    if i>=0.5:\n",
        "      pred_class.append(1)\n",
        "    else:\n",
        "      pred_class.append(0)\n",
        "  return pred_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8btpiWH7uZJF"
      },
      "source": [
        "cnn_pred_class = get_pred(cnn_model)\n",
        "lstm_pred_class = get_pred(lstm_model)\n",
        "knn_pred_class = kn.predict(X_test)\n",
        "sv_pred_class = sv.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86tBOX9Zu3aX"
      },
      "source": [
        "#hard voting\n",
        "final_pred = []\n",
        "for i in range(len(X_test)):\n",
        "  this_t = [int(cnn_pred_class[i]), int(lstm_pred_class[i]), int(knn_pred_class[i]), int(sv_pred_class[i])]\n",
        "  try:\n",
        "    p = mode(this_t)\n",
        "  except:\n",
        "    p = this_t[0]\n",
        "  final_pred.append(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXyb11B7zo0r",
        "outputId": "de4111b3-bc43-4d9d-c3e1-eb872dd17a16"
      },
      "source": [
        "accuracy = accuracy_score(y_test,final_pred)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "precision = precision_score(y_test, final_pred)\n",
        "print('Precision: %f' % precision)\n",
        "\n",
        "recall = recall_score(y_test,final_pred)\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "f1 = f1_score(y_test,final_pred)\n",
        "print('F1 score: %f' % f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.795620\n",
            "Precision: 0.778226\n",
            "Recall: 0.694245\n",
            "F1 score: 0.733840\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwORa1Q106Hl"
      },
      "source": [
        "weighted average ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTVDxgsY0usK"
      },
      "source": [
        "cnn_pred = cnn_model.predict(X_test)\n",
        "lstm_pred = lstm_model.predict(X_test)\n",
        "knn_pred = kn.predict_proba(X_test)\n",
        "sv_pred = sv.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOi4DPta1iAU"
      },
      "source": [
        "knn_p = [i[1] for i in knn_pred]\n",
        "sv_p = [i[1] for i in sv_pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSgvqnKM2XcV"
      },
      "source": [
        "final_p = []\n",
        "for i in range(len(X_test)):\n",
        "  this_t = [cnn_pred[i], lstm_pred[i], knn_p[i], sv_p[i]]\n",
        "  p = this_t[0]*0.3 + this_t[1]*0.3 + this_t[2]*0.2 + this_t[3]*0.2\n",
        "  if p>=0.5:\n",
        "    final_p.append(1)\n",
        "  else:\n",
        "    final_p.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkNI4diD3Zb5",
        "outputId": "5ff819cc-06c0-4a36-c3e4-ba8657973efd"
      },
      "source": [
        "accuracy = accuracy_score(y_test, final_p)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "precision = precision_score(y_test, final_p)\n",
        "print('Precision: %f' % precision)\n",
        "\n",
        "recall = recall_score(y_test,final_p)\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "f1 = f1_score(y_test,final_p)\n",
        "print('F1 score: %f' % f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.880273\n",
            "Precision: 0.933107\n",
            "Recall: 0.762376\n",
            "F1 score: 0.839146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmnlRUIU-PPS"
      },
      "source": [
        "# submit for kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cld9eo1E-OCG",
        "outputId": "98da0bf3-ae77-4685-a1c2-6763cf86dd2f"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "maxlen = 100\n",
        "max_words = 10000\n",
        "\n",
        "tokenizer=Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(test)\n",
        "sequences = tokenizer.texts_to_sequences(test)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7578 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptKD2BqN-hcS",
        "outputId": "feb2e90e-eb15-4089-c85c-a29c173415b4"
      },
      "source": [
        "glove_dir = '/content/gdrive/My Drive/AI Lecture/'\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "# preparing the GloVe word-embeddings matrix\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if i < max_words:\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_Ac2CUw-t3G"
      },
      "source": [
        "sample_x = pad_sequences(sequences,maxlen=maxlen,truncating='post',padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuvbUdO2BML4",
        "outputId": "77c95d51-c80d-4219-c752-9c5ab3a4130b"
      },
      "source": [
        "len(sample_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3263"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFc830p6_Bwf"
      },
      "source": [
        "cnn_pred = cnn_model.predict(sample_x)\n",
        "lstm_pred = lstm_model.predict(sample_x)\n",
        "knn_pred = kn.predict_proba(sample_x)\n",
        "sv_pred = sv.predict_proba(sample_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkTzBSvC_EY0"
      },
      "source": [
        "knn_p = [i[1] for i in knn_pred]\n",
        "sv_p = [i[1] for i in sv_pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bewRYZrd_GVc"
      },
      "source": [
        "y = []\n",
        "for i in range(len(sample_x)):\n",
        "  this_t = [cnn_pred[i], lstm_pred[i], knn_p[i], sv_p[i]]\n",
        "  p = this_t[0]*0.3 + this_t[1]*0.3 + this_t[2]*0.2 + this_t[3]*0.2\n",
        "  if p>=0.5:\n",
        "    y.append(1)\n",
        "  else:\n",
        "    y.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jd8nr3n_X1d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "y=np.round(y).astype(int).reshape(3263)\n",
        "sub=pd.DataFrame({'id':test_data['id'].values.tolist(),'target':y})\n",
        "sub.to_csv('/content/gdrive/My Drive/AI Lecture/kaggle_nlp_submission.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5u6Od6sOco"
      },
      "source": [
        "# Plotting models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z20E5xRY8pC3"
      },
      "source": [
        "model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoLIrxmtr-PS"
      },
      "source": [
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhimaspA8rmh"
      },
      "source": [
        "validation data/ train data graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "DH29izris1M8",
        "outputId": "43a350cd-82ab-48fd-b039-d3355244482f"
      },
      "source": [
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc =history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss =  history.history['val_loss']\n",
        "\n",
        "epochs  = range(1,len(acc)+1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='validation acc')\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSvDDuso8lok"
      },
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZG9riiM7Zie",
        "outputId": "e7e69b38-e239-4bf5-874c-40bf66fd93d5"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cf = confusion_matrix(y_test,final_p)\n",
        "cf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[376,  31],\n",
              "       [ 98, 180]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WcWQeyQ07Npd",
        "outputId": "cb35ea07-0bda-472b-c3e8-68e123bcf49d"
      },
      "source": [
        "import itertools\n",
        "plt.imshow(cf,cmap=plt.cm.Blues,interpolation='nearest')\n",
        "plt.colorbar()\n",
        "plt.title('Confusion Matrix without Normalization')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "tick_marks = np.arange(len(set(final_p)))\n",
        "class_labels = ['0','1']\n",
        "tick_marks\n",
        "plt.xticks(tick_marks,class_labels)\n",
        "plt.yticks(tick_marks,class_labels)\n",
        "# plotting text value inside cells\n",
        "thresh = cf.max() / 2.\n",
        "for i,j in itertools.product(range(cf.shape[0]),range(cf.shape[1])):\n",
        "    plt.text(j,i,format(cf[i,j],'d'),horizontalalignment='center',color='white' if cf[i,j] >thresh else 'black')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybWOVMqFltDf"
      },
      "source": [
        "#F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEx2jAFllr_w"
      },
      "source": [
        "pred_prob = saved_model.predict(X_test)\n",
        "pred_prob = pred_prob[:, 0]\n",
        "pred_class = []\n",
        "for i in pred_prob:\n",
        "  if i>=0.5:\n",
        "    pred_class.append(1)\n",
        "  else:\n",
        "    pred_class.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq08deqMp4k0",
        "outputId": "33b1fa02-df77-40fc-f147-92af3ee743f4"
      },
      "source": [
        "accuracy = accuracy_score(y_test, pred_class)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "precision = precision_score(y_test, pred_class)\n",
        "print('Precision: %f' % precision)\n",
        "\n",
        "recall = recall_score(y_test, pred_class)\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "f1 = f1_score(y_test, pred_class)\n",
        "print('F1 score: %f' % f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.807299\n",
            "Precision: 0.861386\n",
            "Recall: 0.625899\n",
            "F1 score: 0.725000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrntdjToZbTe"
      },
      "source": [
        "# references"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PHh4Zc-IC2D"
      },
      "source": [
        "preprocessing:  https://www.kaggle.com/shahules/basic-eda-cleaning-and-glove\n",
        "\n",
        "spelling correction: https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SPELL_CHECKER_EN.ipynb#scrollTo=uAiXj3DOfyZ-\n",
        "\n",
        "second cnn model(multi input) : https://www.kaggle.com/au1206/text-classification-using-cnn  \n",
        "-> We basically add different convolution layers of filter sizes [3, 4, 5], this somewhat emulates different skip-gram models where different filter sizes essentially means the number of words the filter is being applied to.\n",
        "\n",
        "cnn text classification : https://medium.com/voice-tech-podcast/text-classification-using-cnn-9ade8155dfb9\n",
        "\n",
        "tuning a model : https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
        "\n",
        "ensemble method : https://www.toptal.com/machine-learning/ensemble-methods-machine-learning#:~:text=Majority%20Voting,stable%20prediction%20for%20this%20instance.\n",
        "\n",
        "confusion matrix: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9h3oQ_tA3y8"
      },
      "source": [
        "#contribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NFANw-zA61o"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmAyP479A7WB"
      },
      "source": [
        "#git repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfcTD7fIFdiS",
        "outputId": "91d1fb07-6a47-4d65-f0ff-87a6e5435a67"
      },
      "source": [
        "!git init"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reinitialized existing Git repository in /content/.git/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QTTjHk4Fp3m"
      },
      "source": [
        "!git config --global user.email \"ramda4415@gmail.com\"\r\n",
        "!git config --global user.name \"myamaak\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtKUinF8FqSB"
      },
      "source": [
        "!git add -A"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgGQONEnGQLA",
        "outputId": "bddf45c7-da89-45d3-f1fa-6ce9976ba70a"
      },
      "source": [
        "!git commit -m \"first commit\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch master\n",
            "nothing to commit, working tree clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtbY_NuiGgw2"
      },
      "source": [
        "!git remote add origin https://myamaak:ekdud1986!@github.com/myamaak/NLP_disaster_tweets.git"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x1l9itnGxs6",
        "outputId": "a85a5916-276f-4bf8-99e6-571dca9e04fe"
      },
      "source": [
        "!git push -u origin master"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting objects: 27, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (19/19), done.\n",
            "Writing objects: 100% (27/27), 8.42 MiB | 2.41 MiB/s, done.\n",
            "Total 27 (delta 4), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (4/4), done.\u001b[K\n",
            "To https://github.com/myamaak/NLP_disaster_tweets.git\n",
            " * [new branch]      master -> master\n",
            "Branch 'master' set up to track remote branch 'master' from 'origin'.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}